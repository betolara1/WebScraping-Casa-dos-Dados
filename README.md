# ğŸ” WebScraping â€” Casa dos Dados

> Script de **web scraping** em Python + Selenium que coleta automaticamente dados cadastrais de empresas a partir de CNPJs, extraindo informaÃ§Ãµes do portal [Casa dos Dados](https://casadosdados.com.br).

---

## ğŸ“Œ Objetivo & Problema

| | DescriÃ§Ã£o |
|---|---|
| **Problema** | Consultar manualmente dados de empresas (razÃ£o social, e-mail, telefone, endereÃ§o) pelo CNPJ no site Casa dos Dados Ã© lento e inviÃ¡vel para grandes volumes. |
| **SoluÃ§Ã£o** | Automatizar a coleta via Selenium, lendo uma lista de CNPJs de um arquivo CSV e exportando os resultados estruturados para outro CSV â€” pronto para anÃ¡lise ou importaÃ§Ã£o em CRMs. |

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WebScraping Pipeline                      â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ dados.csv  â”‚â”€â”€â”€>â”‚     main.py      â”‚â”€â”€â”€>â”‚  clientes.csv    â”‚  â”‚
â”‚  â”‚  (input)   â”‚    â”‚  Selenium Driver â”‚    â”‚    (output)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                             â”‚                                    â”‚
â”‚                             â–¼                                    â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                  â”‚  casadosdados.com.br â”‚                         â”‚
â”‚                  â”‚   (fonte de dados)  â”‚                         â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fluxo:**
1. O script lÃª cada linha do `dados.csv` (slug: razÃ£o social + CNPJ).
2. Abre o Chrome via **Selenium + WebDriver Manager**.
3. Acessa a pÃ¡gina do CNPJ no Casa dos Dados.
4. Extrai os campos via **XPath** (nome, e-mail, telefone, endereÃ§o).
5. Grava os dados extraÃ­dos no arquivo `clientes.csv`.

---

## ğŸš€ Como Rodar

### PrÃ©-requisitos

- **Python 3.8+**
- **Google Chrome** instalado
- **pip** (gerenciador de pacotes)

### InstalaÃ§Ã£o (Dev)

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/betolara1/WebScraping-Casa-dos-Dados.git
cd WebScraping-Casa-dos-Dados

# 2. (Recomendado) Crie um ambiente virtual
python -m venv venv
source venv/bin/activate        # Linux/macOS
venv\Scripts\activate           # Windows

# 3. Instale as dependÃªncias
pip install -r requirements.txt
```

### ExecuÃ§Ã£o

```bash
python main.py
```

> O script lÃª o arquivo `dados.csv`, processa cada CNPJ e grava os resultados em `clientes.csv`.

### Docker (ProduÃ§Ã£o)

```bash
# Build da imagem
docker build -t webscraping-casa-dos-dados .

# ExecuÃ§Ã£o do container
docker run --rm \
  -v $(pwd)/dados.csv:/app/dados.csv \
  -v $(pwd)/clientes.csv:/app/clientes.csv \
  webscraping-casa-dos-dados
```



```dockerfile
FROM python:3.11-slim

# Instala Chrome e dependÃªncias do sistema
RUN apt-get update && apt-get install -y \
    wget gnupg unzip curl \
    && wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "main.py"]
```

</details>

---

## ğŸ“Š Exemplos de Input / Output

### Input â€” `dados.csv`

Cada linha contÃ©m o slug no formato `RAZAO-SOCIAL-CNPJ`:

```csv
CARLOS-ANDREI-SOARES-DE-PINHO-15171393000173
GRUPO-DE-ARTES-ESSENCIA-NATIVA-15139244000127
```

### URL gerada pelo script

```
https://casadosdados.com.br/solucao/cnpj/CARLOS-ANDREI-SOARES-DE-PINHO-15171393000173
```

### Output â€” `clientes.csv`

```csv
Nome Fantasia: EMPRESA EXEMPLO
RazÃ£o Social: EMPRESA EXEMPLO LTDA
Email: contato@empresa.com
Telefone: (62) 3333-4444
Rua: Rua das Flores
NÃºmero: 123
Complemento: Sala 01
Bairro: Centro
Cidade: GoiÃ¢nia
```

### Dados extraÃ­dos por CNPJ

| Campo | XPath | Exemplo |
|---|---|---|
| Nome Fantasia | `div[3]` | EMPRESA EXEMPLO |
| RazÃ£o Social | `div[4]` | EMPRESA EXEMPLO LTDA |
| E-mail | `div[19]` | contato@empresa.com |
| Telefone | `div[20]` | (62) 3333-4444 |
| Logradouro | `div[12]` | Rua das Flores |
| NÃºmero | `div[13]` | 123 |
| Complemento | `div[14]` | Sala 01 |
| Bairro | `div[15]` | Centro |
| Cidade | `div[17]` | GoiÃ¢nia |

---

## ğŸ“ Estrutura do Projeto

```
WebScraping-Casa-dos-Dados/
â”œâ”€â”€ main.py              # Script principal de scraping
â”œâ”€â”€ dados.csv            # Arquivo de entrada (slugs CNPJ)
â”œâ”€â”€ clientes.csv         # Arquivo de saÃ­da (gerado apÃ³s execuÃ§Ã£o)
â”œâ”€â”€ requirements.txt     # DependÃªncias Python
â”œâ”€â”€ Dockerfile           # ContainerizaÃ§Ã£o
â”œâ”€â”€ .dockerignore        # Arquivos ignorados no build
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml       # Pipeline CI (lint + testes)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_main.py     # Testes unitÃ¡rios (pytest)
â””â”€â”€ README.md            # Esta documentaÃ§Ã£o
```

---

## ğŸ§ª Testes

Os testes estÃ£o em `tests/test_main.py` e cobrem:

- âœ… ValidaÃ§Ã£o do CSV de entrada (existÃªncia, formato, slugs)
- âœ… GeraÃ§Ã£o correta de URLs
- âœ… ConversÃ£o de lista para string (limpeza de colchetes)
- âœ… CriaÃ§Ã£o e escrita do arquivo de saÃ­da
- âœ… MÃºltiplas entradas gravadas corretamente

**Rodar os testes:**

```bash
pip install pytest
pytest tests/ -v
```

---

## âš™ï¸ GitHub Actions (CI)

Pipeline configurada em `.github/workflows/ci.yml`:

- **Trigger:** push/PR na branch `main`
- **Lint:** `flake8` no `main.py`
- **Testes:** `pytest tests/ -v`
- **Python:** 3.11 no Ubuntu latest

---

## ğŸ› ï¸ Tecnologias

| Tecnologia | VersÃ£o | Uso |
|---|---|---|
| Python | 3.8+ | Linguagem principal |
| Selenium | 4.14.0 | AutomaÃ§Ã£o do navegador |
| WebDriver Manager | 4.0.1 | Gerenciamento automÃ¡tico do ChromeDriver |
| Google Chrome | latest | Navegador para scraping |

---

## âš ï¸ ObservaÃ§Ãµes Importantes

- **Rate Limiting:** Recomenda-se adicionar `time.sleep()` entre as requisiÃ§Ãµes para evitar bloqueio pelo site.
- **XPaths frÃ¡geis:** Os seletores XPath podem quebrar se o site mudar a estrutura HTML. Monitore e atualize conforme necessÃ¡rio.
- **Uso Ã©tico:** Respeite os termos de uso do site e faÃ§a scraping de forma responsÃ¡vel.
- **Dados pessoais:** Os dados coletados (e-mail, telefone) sÃ£o sensÃ­veis â€” utilize-os em conformidade com a LGPD.

---

## ğŸ‘¤ Autor

- GitHub: [@betolara1](https://github.com/betolara1)

---

â­ Se este projeto te ajudou, considere dar uma estrela no GitHub!
